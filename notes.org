#+AUTHOR: Andrea Crotti
#+TITLE: Gentle introduction to Functional Programming
#+OPTIONS: num:nil ^:nil tex:t toc:nil reveal_progress:t reveal_control:t reveal_overview:t
#+REVEAL_TRANS: fade
#+REVEAL_SPEED: fast
#+EMAIL: andrea.crotti.0@gmail.com
#+TOC: listings

* 
  :PROPERTIES:
  :reveal_background: ./images/should_learn.jpg
  :reveal_background_trans: slide
  :reveal_background_size: 800px
  :END:

#+BEGIN_NOTES
In the last few years there has been a lot of hype about functional programming.

Many languages like Clojure or Scala are growing extremely fast in popularity and many big companies
are moving more and more to functional programming.

And this affects anyone, if you look at some job postings it's almost certain that they will contain
a functional programming exposure or knowledge (even the Python engineer job post here at Skimlinks does).
#+END_NOTES


* What?

#+BEGIN_NOTES
So let's start to talk about what is functional programming which will help understanding why
it's becoming so important in the software world.
Functional programming is a full model of computation based on lambda calculus.
This means that it's a model that can represent anything that is computable, in the same
way as a turing maching can (or any language that is usually defined Turing Complete).

We might see in more detail an example about Lambda calculus later on if we have time.

In functional programming are the building block and always considered first class citizens.
You also need to be able to define higher order functions, and perform partial appliaction and currying.

Functions also need to be pure, which means that there is no external state that affects them,
and the data has to be immutable.
Any side effect should be then in fact encapsulated.

Another very common building block of FP are lazy sequences, which work extremely well with
immutability.
#+END_NOTES

  - Programming paradigm based on *lambda calculus* (Alonzo Church)

  - /functions/ are *first class* citizens
    - higher-order functions
    - partial application
    - currying

  - Functions are *pure*
    - immutable data: *no state*
    - encapsulated side effects

  - lazy sequences

** You shall NOT have

#+BEGIN_NOTES
There is another way to define functional programming, which is in term of the constraints that are added.
There is a very interesting talk from Bob Martin where he points out that every paradigm shift brings
a new set of constraints, which overall make our lives a lot better.

As OOP took away from use the GOTO statement, these are the things that you shall not do in functional
programming.
#+END_NOTES

 - Assignments
 - Mutable data structures
 - While/For Loops
 - Control Over Order of Execution
 - Side Effects

[[./images/wtf.gif]]


* Why?

** Give me a reason

#+BEGIN_NOTES
So after we briefly introduced what is functional programming we are going
to say why it is becoming so important and prevalent.

Functional programming is even older than OOP and for many years it was
considered a niche environment, but probably the biggest change
that caused everyone to jump on the FP train is the multicore revolution.

When even your watch has multiple cores being able to write safe concurrent
code becomes very important, and the traditional ways (using threads, locks,
and so on and so forth) are just terrible and will ruin your life.

On top of that programming has become more and more complex, and OOP
programs just don't compose well.

The code you will write if you learn FP will be also definitively better,
more testable and more reusable then the one you are used to write.

#+END_NOTES

# [[./images/why.gif]]

  - threading sucks
  - OOP does not compose
  - write *better* code
  - it's the next big paradigm shift (and it's already happening)
  - you are already doing it

# TODO: show an example about how hard is to write concurrent code?

** OOP is dead


#+BEGIN_NOTES
About OOP this is a quote from a professor of the Carniage Mellon
University which expresses this view quite clearly.

OOP is still the taught in all universisties but luckily some
of them are starting to realise that it's not what we need anymore.
#+END_NOTES

 [[./images/oop_rip.jpg]]

 #+begin_quote
 Object-oriented programming is both anti-modular and
 anti-parallel by its very nature, and hence unsuitable for a modern CS
 curriculum.

  Robert Harper (professor at Carniage Mellon University)

 #+end_quote

* What is a function

#+BEGIN_NOTES
So since we said that FP is based on functions, let's have a look again at what
functions are in their mathematical terms.

From this example the function f takes an input x and return a value
that depends on it.

The output of f depends only on the input we pass in, and this function
has no side effects.

The other important property of a function is referential transparency,
which means that for a function defined as such you can always replace
the function call by its result, and the end result of the program
will still be exactly the same.
#+END_NOTES

$f(x) = 2 x + 1$

- output depends *only* on the input
- no side effect -> *pure*

$f(4) = 9$

- *referential transparency*:
  a function call can be always replaced by its result

** Side effects

#+BEGIN_NOTES
Previously we talked about side effects and referential transparency,
I'll just give an example to clarify these two concepts in Python.
The first example is a simple adder, but after doing the actual addition
it also writes out to disk, which is a side effect, thus the function is not pure.

The second one instead is interesting because even though it does not have
side effects, it's not referential transparent because the return value
depends on a global dictionary.
Since that dictionary is mutable any other code could modify that at any time,
and so the function is not referentiall transparent.
#+END_NOTES


Side effect:
#+begin_src python :tangle python_samples.py
  def adder(x, y):
      res = x + y
      open('output.txt', 'w').write(str(res))
      return res
#+end_src

*Non* referential transparent:

#+begin_src python :tangle python_samples.py
  SETTINGS = {'counter': 1}

  def increment(inc_value):
      return SETTINGS['counter'] + inc_value
#+end_src

** Domains

#+BEGIN_NOTES

Another important thing to consider is that every pure function
is that it has a domain and a codomain, so it always transforms
values of type X to values of type Y.

Not all FP programming languages are statically typed but types
are always present anyway and you should always keep them in mind
when you're writing your code.
As we can see later types are also a very important help in writing
correct code, and test it more easily.
#+END_NOTES

[[./images/domain.png]]

* Functional languages

#+BEGIN_NOTES
Here a short list of other interesting functional programming languages
that have been getting a lot of traction recently.

They all have slightly different constraints and approaches, but overall
they all focus on immutability and function composition as the main
way to write complex code.
#+END_NOTES

  - Haskell
  - Clojure
  - Scala
  - F#
  - Erlang
  - Elixir
  - Elm

* Haskell (1990)

#+BEGIN_NOTES
The original intention was to talk about Python but in reality
my first real encounter with FP was with Haskell and that's probably
the main reason why I got interested in it.

Haskell is a relatively old language (same age as Python) but it has
been for most of its history a niche research language, that people
used to write papers with.

It's probably until now the most "complete" and pure functional programming
language out there, and in some ways it's just incredibly beautiful.

This joke here refers to the fact that while there is so much interest in
Haskell not as many people use it in production, but in any case
it's still probably the best language to really learn functional programming.
#+END_NOTES

  - pure
  - lazy
  - pattern matching
  - algebraic data types
  - type inference

[[./images/haskell.png]]

** Fibonacci

#+BEGIN_NOTES
Let's just see a couple of examples of haskell code.
First of all we can define a fibonacci function that computes
the nth fibonacci number, and does it recursively.

This first definition is incredibly simple and is just
the same as the mathematical definition.
First we define the type above, which means that fib is a function
that takes an int and returns another int.

And then we define top-down the output of the function itself,
first with two specific values (using pattern matching) and then
in the generic case.
#+END_NOTES


#+begin_src haskell
  fib :: Int -> Int
  fib 0 = 0
  fib 1 = 1
  fib n = fib (n-1) + fib (n-2)
#+end_src


** Fibonacci stream

#+BEGIN_NOTES
The second function is even more interesting since it condense in two lines
the essence of all the beauty.

Now instead of defining fibs recursively straight away we instead define
the whole fibonacci sequence, recursively as an infinite list of ints!
The way this works is that we use the : to create a list and concatenate
0 and 1 to the result of zipWith (+) fibs (tail fibs).
#+END_NOTES

Or better:

#+begin_src haskell :tangle haskell_samples.hs
  -- zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
  fibs:: [Int]
  fibs = 0 : 1 : zipWith (+) fibs (tail fibs)

  -- get the 10th fibonacci number from
  fib :: Int -> Int
  fib n = fibs !! n
#+end_src

Which in Python is roughly:

#+begin_src python :tangle python_samples.py
  first_fibs = [0, 1, 2, 3, 5]

  fibs = [0, 1] + list(map(sum, zip(first_fibs, first_fibs[1:])))
  # Out[5]: [0, 1, 1, 2, 3, 5, 8]
#+end_src

#+RESULTS:

** Quicksort

#+BEGIN_NOTES
Now let's have a quick look at another example, the famous quicksort algorithm.
It's a recursive algorithm and this here is the pseudocode.

The version below is the actual full implementation in Haskell of the same algorithm.
A couple of interesting things here, the pattern matching in the input matches on
the first element of the list and all the rest.

And the other interesting thing is that the type signature is completely generic now.
Anything that is instance of the class Ord can be passed and you will get as return
a new list with elements of the same type sorted.
While this is not a really clever or fast implementation it's still incredibly concise
and readable.
#+END_NOTES

Pseudocode:

#+begin_src python
  quicksort(A, lo, hi)
      if lo < hi
          p := pivot(A, lo, hi)
          left, right := partition(A, p, lo, hi)
          quicksort(A, lo, left)
          quicksort(A, right, hi)
#+end_src

Haskell:

#+begin_src haskell :tangle haskell_samples.hs
  quicksort :: (Ord a) => [a] -> [a]
  quicksort [] = []
  quicksort (x:xs) =
      let smallerSorted = quicksort [a | a <- xs, a <= x]
          biggerSorted = quicksort [a | a <- xs, a > x]

      in  smallerSorted ++ [x] ++ biggerSorted
#+end_src

* Python vs Haskell

#+BEGIN_NOTES
Taking Haskell as the ideal functional programming language, what are the
differences between Haskell and Python, or better what does Python actually
supports.
#+END_NOTES

  - ✓ functions first class citizens
  - ✓ lazy sequences (kind of)
  - ❌ immutability (partial)
  - ❌ Algebraic data types
  - ❌ side effects encapsulation
  - ❌ type inference

** Screwed?

#+BEGIN_NOTES
So the question is, can we do any functional programming in Python?
The answer is of course yes, even if we won't have all the nice things
that other languages have we will still get many of the advantages anyway.
#+END_NOTES

[[./images/screwed.png]]

** Functions

#+BEGIN_NOTES
So let's start from functions as first class citizens.
That is entirely true in Python, however we have 5 different ways
to define a function, and I just want to first clarify what
each of them mean and how they work.
#+END_NOTES

- function
- lambda
- classmethod
- method
- staticmethod

*Demo time*
# [[./images/confused.gif]]

*** Partial application

#+BEGIN_NOTES
One important building block is higher order functions and partial
application.
In the Python standard library there is a module called functools
which has some nice functions, and one of them is functools.partial.
#+END_NOTES

*functools.partial*

#+begin_src python :tangle python_samples.py

  import functools, operator

  def mul(x, y):
      return x * y

  mul(3, 10) # 30

  mulby3 = functools.partial(operator.mul, 3)
  mulby3(10) # 30
#+end_src

Equivalent to:

#+begin_src python :tangle python_samples.py
  def mulby3(x):
      return mul(x, 3)
#+end_src

** Lazy sequences

#+BEGIN_NOTES
Infinite streams are a very nice thing to use, because they really
encapsulate the essence of the sequence, without having to worry
about termination conditions.

This is an example of a fibonacci numbers generator in Python,
more or less equivalent to what we had seen previously in Haskell.

The generator is defined by yielding a new value every time lazily.
The itertools.islice function then will take a slice from
the 10th to the 100th element of this infinite stream, without
having to realize it completely.
Many other useful functions like takewhile/dropwhile/chain and
so on and so forth are also part of this module.
#+END_NOTES

   - generators
   - itertools

#+begin_src python :tangle python_samples.py
  import itertools

  def fib_gen():
      a, b = 0, 1
      yield a
      while True:
          yield b
          a, b = b, a + b

  for num in itertools.islice(fib_gen(), 10, 100):
      print(num)
#+end_src

** Map

#+BEGIN_NOTES
As we said in the beginning one of the typical constraints of
FP is the lack of for/while loops.
A loop can just be translated by a transformation on an iterable
instead.
Map and reduce (together with many more) are part of the standard
library and are bulding blocks of Spark for example (not a concidence
since Spark is written in Scala that is a functional language).

So suppose we want to transform a list doubling all the elements.
We can either do a simple loop and accumulate on a new list, use
a list comprehension as shown here or we can get rid of loops completely.

Here we first define the double function as a partial application
and then apply that to the given list.
#+END_NOTES

 Standard for loop:

#+begin_src python :tangle python_samples.py
  lis = [1, 2, 3, 4]

  newlis = []
  for l in lis:
      newlis.append(l * 2)

#+end_src

List comprehension:

#+begin_src python :tangle python_samples.py
  [l * 2 for l in lis]
#+end_src

Look mum no loop:

#+begin_src python :tangle python_samples.py
  import operator
  mul_by_two = functools.partial(operator.mul, 2)
  map(mul_by_two, lis)
#+end_src

** Reduce

#+BEGIN_NOTES
Another important operation is reduce, which a function cumulatively
to the items of a sequence from left to right, reducing the list
to a single value.
This is the loopy version and below the same operation done using reduce.
#+END_NOTES

Loopy:

#+begin_src python :tangle python_samples.py
  lis = [1, 2, 3, 4]

  val = 0
  for l in lis:
      val += 0

#+end_src

Not loopy:

#+begin_src python :tangle python_samples.py
  val = functools.reduce(operator.add, lis)
#+end_src

** Immutability and toolz

#+BEGIN_NOTES
Immutability is extremely important for functional programming, and while
sadly in Python it's not really possible to ensure immutability, we can
still try to never mutate by convention.

One of the most commonly used data structures for example is a dictionary,
which is by its very nature mutable.
If we use toolz however it will give us the ability to stop mutating dictionaries
and just creating new copies of them very easily.

Let' see now for example a simple dictionary, and all we want to do do
is to increment all the values.
The most "normal" way would be too loop over key and values and modify it
inline, but another way would be to use toolz.valmap that creates a
new dictionary and maps the function we pass in to.
#+END_NOTES

   Toolz is a collection of utility functions inspired from FP languages.

#+begin_src python :tangle python_samples.py
  import toolz

  bills = {
      "Alice": 0,
      "Bob": 1,
  }
#+end_src

MUTABLE:

#+begin_src python :tangle python_samples.py
    def change_inline(bills):
        for key, val in bills.items():
            bills[key] = val + 1
#+end_src

IMMUTABLE:

#+begin_src python :tangle python_samples.py
  def change_immutable(dic):
      inc = functools.partial(operator.add, 1)
      return toolz.valmap(inc, dic)
#+end_src

** Other toolz functions

|----------------+------------+-----------+------------|
| assoc          | dissoc     | itemmap   | itemfilter |
| merge          | merge_with | valfilter | valmap     |
| partition      | groupby    | juxt      | take       |
| sliding_window | compose    | diff      | drop       |
| interspose     | interleave | ...       |            |

* Simple example

#+BEGIN_NOTES
Let's look at a very simple example of how you can implement
the same thing with a class or with simple functions.

We have a class transformer that takes a collection, a method
func and a method transform that calls func on the data.
So what are the problems with this, well first the func
method does not need to be a method, and second the transform
is modifying self.data itself without returning it.

But more importantly what are we gaining by using classes here?

#+END_NOTES

** OOP

#+begin_src python :tangle python_samples.py

  class Transformer(object):
      def __init__(self, collection):
          self.data = collection

      def func(self, collection):
          return filter(lambda x: x % 2 ==0, collection)

      def transform(self):
          self.data = self.func(self.data)

  tr = Transformer(range(10))
  tr.transform()
  tr.data

#+end_src

** FP

#+BEGIN_NOTES
Probably nothing from that example really because it can be much more
easily all done just by composing functions as seen here.
#+END_NOTES


#+begin_src python :tangle python_samples.py
  def evens(collection):
      return filter(lambda x: x % 2 ==0, collection)

  def transform(func, collection):
      return func(collection)

  transform(evens, range(10))
#+end_src

* Refactor journey


#+BEGIN_NOTES
So now let's have a look at another example, starting from something
that might look familiar and understanding what are the issues with it.

The previous example was a bit trivial since it didn't really involve
any side effect, so we can instead look at something that involves side
effects, and see what we can do to improve that anyway.
#+END_NOTES

** The mess

#+BEGIN_NOTES
This function simplyh list files in the filesystem, and if a filename contains the string to-match
it writes it out to the database.
The first interesting thing is that the name of the function is long_crappy_function, and
the reason for that is that since it clearly does too many things it's not really
easy in general to give it a name.

So assuming we have some integration tests (if not we would write some) that allow
us to refactor this without breaking everything, we can start by splitting this in three
components.
#+END_NOTES


#+begin_src python :tangle python_samples.py
  import subprocess, sqlite3

  def long_crappy_function():
      ## launching a shell command
      ls_cmd = 'ls'
      p = subprocess.Popen(ls_cmd,
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE)
      ## filtering the output of a shell command
      out, err = p.communicate()
      res = []
      for line in out.decode('utf-8').splitlines():
          if 'to-match' in line:
              res.append(line)

      ## updating the results to database
      dbc = sqlite3.connect("lambda.db")
      cursor = dbc.cursor()

      for r in res:
         cursor.execute('INSERT INTO table VALUES (%s)' % r)

#+end_src

** Extract 'ls' execution

#+BEGIN_NOTES
First we get the output from ls in a way that is already easy to process,
as a list of unicode strings
#+END_NOTES

#+begin_src python :tangle python_samples.py

  def run_ls():
      ## launching a shell command
      ls_cmd = 'ls'
      p = subprocess.Popen(ls_cmd,
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE)
      ## filtering the output of a shell command
      out, err = p.communicate()
      return out.decode('utf-8').splitlines()

#+end_src

** Extract database update

#+BEGIN_NOTES
The we write the function that writes to the database.
#+END_NOTES


#+begin_src python :tangle python_samples.py

  def update_to_database(res):
      ## updating the results to database
      dbc = sqlite3.connect("lambda.db")
      cursor = dbc.cursor()

      for r in res:
         cursor.execute('INSERT INTO table VALUES (%s)' % r)
 #+end_src

** Extract filter output

#+BEGIN_NOTES 
And finally we can write out the filtering function, which is now written
in this loop style, but can be written also just as a simple filter.
#+END_NOTES


#+begin_src python :tangle python_samples.py


  def filter_output(out):
      res = []
      for line in out:
          if 'to-match' in line:
              res.append(line)

      return res

#+end_src

Or even better:

#+begin_src python :tangle python_samples.py

  def filter_output(out):
      return filter(lambda l: 'to-match' in l, out)

  # or using partial application
  def filter_output2(out):
      match_function = functools.partial(operator.contains, 'to-match')
      return filter(match_function, out)
#+end_src

** Now test this

#+BEGIN_NOTES
The important thing is that now we can actually write unit tests
for this, in a way that we were not able todo before.
The filter_output function in fact does not care about the filesystem,
and does not care about the database, all it needs is a list of strings.
#+END_NOTES

 Unit tests becomes *possible*

 #+begin_src python :tangle python_samples.py

   def filter_output(out):
       return filter(lambda l: 'to-match' in l, out)

   def test_filter_output():
       lines = ['x1: to-match', 'x2', 'x3: to-match..']
       desired = ['x1: to-match', 'x3: to-match..']
       assert filter_output(lines) == desired

 #+end_src


** And finally

#+BEGIN_NOTES
And now we can put it all back together writing a simple pipe.
#+END_NOTES


#+begin_src python :tangle python_samples.py
  def write_filtered_ls_to_db():
      """Do a bit of everything
      """
      out = run_ls()
      res = filter_output(out)
      update_to_database(res)
#+end_src

* Find the diamond

** In the beginning

#+begin_src python
  def merge_part_files():
      merged_key = output_bucket.initiate_multipart_upload(output_key)
      chunk = StringIO()
      parts = 0
      for key in input_bucket.list(input_prefix):
          if key.name.endswith(".gz"):
              if key.size < FIVE_MEGABYTES:
                  chunk.write(key.get_contents_as_string())
                  if chunk.len > FIVE_MEGABYTES:
                      chunk.seek(0)
                      parts += 1
                      merged_key.upload_part_from_file(chunk, parts)
                      chunk.close()
                      chunk = StringIO()
              else:
                  parts += 1
                  merged_key.copy_part_from_key(input_bucket.name, key.name,
                                                parts)
      if chunk.len:
          chunk.seek(0)
          parts += 1
          merged_key.upload_part_from_file(chunk, parts)
          chunk.close()
#+end_src

** Fix the bug

#+begin_src python
   while idx < len(key_list):
       key = key_list[idx]
       if key.size < CHUNK_SIZE:
           while chunk.len < CHUNK_SIZE:
               chunk.write(key.get_contents_as_string())
               idx += 1
               key = key_list[idx]

           chunk.seek(0)
           _inc(chunk.len)
           out.mp.upload_part_from_file(chunk, out.parts)
           chunk.close()
           chunk = StringIO()

       elif idx < len(key_list):
           _inc(key.size)
           out.mp.copy_part_from_key(input_bucket.name, key.key, out.parts)
           idx += 1
#+end_src

** Extract partitioning

#+begin_src python
@pytest.mark.parametrize(('input', 'expected'), [
    ([Key('a', 10), Key('b', 20), Key('c', 50), Key('d', 60)],
     [[Key('a', 10), Key('b', 20), Key('c', 50)], Key('d', 60)]),
    ([Key('a', 40), Key('b', 40), Key('c', 20)],
     # in this case the second partition is not greater than threshold
     # but there is no alternative without a full look-ahead
     [[Key('a', 40), Key('b', 40)], [Key('c', 20)]]),
])
def test_partitioned_list(input, expected):
    assert list(s3_utils.partition_list(input, threshold=50)) == expected

#+end_src

#+begin_src python
  def partition_list(lis, threshold):
      chunk, partial = [], 0
      idx = 0
      while idx < len(lis):
          if lis[idx].size < threshold:
              while partial < threshold and idx < len(lis):
                  chunk.append(lis[idx])
                  partial += lis[idx].size
                  idx += 1

              yield chunk
              chunk, partial = [], 0
          else:
              yield lis[idx]
              idx += 1

#+end_src

** Use the new abstraction
#+begin_src python
  def merge_part_files():
      for parts in partition_list(key_list, threshold=CHUNK_SIZE):
          if isinstance(parts, list):
              chunk = StringIO()
              for part in parts:
                  chunk.write(part.get_contents_as_string())
                  _inc(out, part.size)

              chunk.seek(0)
              out.mp.upload_part_from_file(chunk, out.parts)
          else:
              _inc(out, parts.size)
              out.mp.copy_part_from_key(input_bucket.name, parts.key, out.parts)
#+end_src

* Conclusions

** Improved

 1. Lock Free Concurrency.
 2. Brevity. (Modular Code)
 3. Lazy Evaluation.
 4. Composability.
 5. Parallelism.
 6. Improved ways of Testing.
 7. Referential Transparency.
 8. Lesser Bugs.

** Random tips
  
   - default to *immutability*
   - think in terms of transformations, not loops
   - compose your programs bottom-up
   - keep side effects and logic *separate*
   - write your tests *first*

* Quotes

** 10 100

 #+BEGIN_QUOTE
 "It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures." —Alan Perlis
 #+END_QUOTE
   
** Describing

#+BEGIN_QUOTE
Functional programming is like describing your problem to a mathematician.
Imperative programming is like giving instructions to an idiot. - Arcus #scheme
#+END_QUOTE

** Cloud

#+BEGIN_QUOTE
  OOP cannot save us from the Cloud Monster anymore. - Ju Gonçalves
#+END_QUOTE

** Functions

#+begin_quote

   Functional Programming is so called because a program consists entirely of functions.

   - John Hughes, Why Functional Programming Matters

#+end_quote

** Python FP

#+BEGIN_QUOTE
using Python for FP it's like looking at a beautiful view through a dirty window - Andrea Crotti

#+END_QUOTE

** Resources

   - Okasaki for persistent data structures
   - All Rich Hickey talks
   - Why functional programming matters


* Extra material
** Lambda calculus primer
   
   Formal system for expressing computation based on
   - function abstraction
   - variable binding and substitution

Church numerals (s = suc):

$0 \equiv \lambda sz. z$

$1 \equiv \lambda sz. s(z)$

$2 \equiv \lambda sz. s(s(z))$

*** Lambda calculus 2
 *Successor*

 \begin{equation}
 S \equiv \lambda wyx. y(wyx)
 \end{equation}
 \begin{equation}
 S(0) \equiv (\lambda wyx.y(wyx))(\lambda sz.z) = 
 \end{equation}

 \begin{equation}
 \lambda yx.y ((\lambda sz. z) yx) = \lambda yx. y(x) \equiv 1
 \end{equation}

 # Local Variables:
 # after-save-hook: (org-reveal-export-to-html)
 # End:

** Immutability

   [[./images/too_many_objects.png]]

*** Persistent data structures 1/2

 #+begin_src haskell :tangle haskell_samples.hs

   xs = [0, 1, 2]
   ys = [3, 4, 5]

 #+end_src

 [[./images/persistent1.png]]

*** Persistent data structures 2/2

 #+begin_src haskell :tangle haskell_samples.hs
   zs = xs ++ ys
 #+end_src

 [[./images/persistent2.png]]

** Pypersistent?

** Currying
*toolz.curry*

#+begin_src haskell :tangle haskell_samples.hs
  mul:: Int -> Int -> Int
  mul x y = x * y

  mulby3:: Int -> Int
  mulby3 = \x -> mul x 3
#+end_src
